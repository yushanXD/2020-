{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CBHG(arg):\n",
    "    tf.reset_default_graph()\n",
    "    is_training = arg.is_training\n",
    "    lr = arg.lr\n",
    "    num_highway = arg.num_highway\n",
    "\n",
    "    x = tf.placeholder(tf.float32,shape=(None,None, 256))\n",
    "    y = tf.placeholder(tf.float32,shape=(None,None, 80))\n",
    "    print(self.x.shape)\n",
    "    #inputs shape:[Batch,T,256]\n",
    "\n",
    "    inputs = tf.layers.dense(x,units=128,activation=None,use_bias=False,name='trans')\n",
    "\n",
    "    convbanks_outputs = conv1d_banks(inputs,K=16,num_units=128,is_training=self.is_training)\n",
    "    #output shape:[Batch,T,128*16]\n",
    "\n",
    "    maxpool_outputs = tf.layers.max_pooling1d(convbanks_outputs,pool_size = 2,strides = 1,padding='same')\n",
    "    #output shape:[Batch,T,128*16]\n",
    "\n",
    "    c1 = Conv1d(inputs = maxpool_outputs,filters = 128,size = 3,activation=tf.nn.relu, scope='conv1d_1')\n",
    "    #output shape:[Batch,T,128]\n",
    "\n",
    "\n",
    "    n1 = tf.layers.batch_normalization(c1,training = self.is_training)\n",
    "    #output shape:[Batch,T,128]\n",
    "\n",
    "    c2 = Conv1d(inputs = n1, filters = 128, size = 3, activation=None, scope='conv1d_2')\n",
    "    #output shape:[Batch,T,128]\n",
    "\n",
    "\n",
    "    n2 = tf.layers.batch_normalization(c2,training = self.is_training)\n",
    "    #output shape:[Batch,T,128]\n",
    "\n",
    "    highway_inputs  = n2 + inputs\n",
    "    #output shape:[Batch,T,128]\n",
    "\n",
    "    for i in range(self.num_highway):\n",
    "        highway_inputs = highway(highway_inputs,num_units=128,scope='highwaynet_{}'.format(i))\n",
    "    #output shape:[Batch,T,128]\n",
    "\n",
    "    bigru_outputs = gru_bi(inputs = highway_inputs,num_units = 128,scope='gru1')\n",
    "    #output shape:[Batch,T,128]\n",
    "\n",
    "    outputs = tf.layers.dense(bigru_outputs,units=80,activation=None,use_bias=False,name='O')\n",
    "    #output shape:[Batch,T,80]\n",
    "    \n",
    "    return outputs\n",
    "        \n",
    "            #self.loss = tf.square(tf.subtract(outputs, self.y, name=None), name=None)\n",
    "#             print(self.loss.shape)\n",
    "            #c = tf.square(self.y - outputs)\n",
    "            self.istarget = tf.to_float(tf.not_equal(self.y,tf.zeros_like(self.y)))\n",
    "            #p = tf.reduce_sum(c * self.istarget,2)\n",
    "            #s = tf.reduce_sum(p,1)\n",
    "            #self.mean_loss = tf.reduce_mean(s)\n",
    "            self.mean_loss = tf.losses.mean_squared_error(self.y,outputs*self.istarget)\n",
    "#            print(self.mean_loss.shape)\n",
    "           # self.istarget = tf.to_float(tf.not_equal(self.y, tf.zeros_like(self.y))) # masking\n",
    "#             print(self.istarget)\n",
    "            \n",
    "           # self.mean_loss = tf.reduce_sum(self.loss * self.istarget) / 64.0\n",
    "#             print(self.mean_loss.shape)\n",
    "           \n",
    "\n",
    "            self.global_step = tf.Variable(0,name='global_step',trainable=False)\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
    "            self.train_op = self.optimizer.minimize(self.mean_loss, global_step=self.global_step)\n",
    "            \n",
    "            tf.summary.scalar('loss',self.mean_loss)\n",
    "            self.merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if self.is_training:\n",
    "            #self.loss = tf.square(tf.subtract(outputs, self.y, name=None), name=None)\n",
    "#             print(self.loss.shape)\n",
    "            #c = tf.square(self.y - outputs)\n",
    "            self.istarget = tf.to_float(tf.not_equal(self.y,tf.zeros_like(self.y)))\n",
    "            #p = tf.reduce_sum(c * self.istarget,2)\n",
    "            #s = tf.reduce_sum(p,1)\n",
    "            #self.mean_loss = tf.reduce_mean(s)\n",
    "            self.mean_loss = tf.losses.mean_squared_error(self.y,outputs*self.istarget)\n",
    "#            print(self.mean_loss.shape)\n",
    "           # self.istarget = tf.to_float(tf.not_equal(self.y, tf.zeros_like(self.y))) # masking\n",
    "#             print(self.istarget)\n",
    "            \n",
    "           # self.mean_loss = tf.reduce_sum(self.loss * self.istarget) / 64.0\n",
    "#             print(self.mean_loss.shape)\n",
    "           \n",
    "\n",
    "            self.global_step = tf.Variable(0,name='global_step',trainable=False)\n",
    "            self.optimizer = tf.train.AdamOptimizer(learning_rate=self.lr)\n",
    "            self.train_op = self.optimizer.minimize(self.mean_loss, global_step=self.global_step)\n",
    "            \n",
    "            tf.summary.scalar('loss',self.mean_loss)\n",
    "            self.merged = tf.summary.merge_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
